"""
üö¶ H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN K·∫∏T XE REAL-TIME
T√°c gi·∫£: Traffic Monitor System
M√¥ t·∫£: H·ªó tr·ª£ 2 ch·∫ø ƒë·ªô:
       1. Import video t·ª´ m√°y local
       2. Nh·∫≠n stream tr·ª±c ti·∫øp t·ª´ phone qua WebSocket
"""

import cv2
import numpy as np
import websocket
import threading
import time
from collections import deque, defaultdict
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import tkinter as tk
from tkinter import filedialog, messagebox
import os

# ==================== C·∫§U H√åNH ====================
VPS_URL = "wss://traffic058.io.vn/receiver"

# Model YOLOv8
YOLO_MODEL = "yolov8n.pt"

# C√°c l·ªõp xe c·∫ßn nh·∫≠n d·∫°ng
CUSTOM_CLASSES = ["car", "motorcycle", "bus", "truck"]

# B·∫£ng quy ƒë·ªïi xe m√°y t∆∞∆°ng ƒë∆∞∆°ng
VEHICLE_EQUIV = {
    "motorcycle": 1,
    "car": 5, 
    "truck": 19,
    "bus": 17
}

# Ng∆∞·ª°ng confidence
CLASS_CONF_THRESHOLDS = {
    "motorcycle": 0.2,
    "car": 0.35,
    "truck": 0.35,
    "bus": 0.35
}

# Ng∆∞·ª°ng c·∫£nh b√°o k·∫πt xe
THRESHOLD_COUNT = 15
THRESHOLD_SPEED = 5.0

# ==================== L·ªöP CH√çNH ====================
class TrafficMonitor:
    def __init__(self, mode="local", video_path=None):
        self.mode = mode  # "local" ho·∫∑c "stream"
        self.video_path = video_path
        self.frame_queue = []
        self.running = True
        self.cap = None
        
        # Load YOLOv8
        print("üì¶ ƒêang t·∫£i m√¥ h√¨nh YOLOv8...")
        self.model = YOLO(YOLO_MODEL)
        print("‚úÖ YOLOv8 ƒë√£ s·∫µn s√†ng!")
        
        # Initialize DeepSORT
        print("üì¶ ƒêang t·∫£i DeepSORT tracker...")
        self.tracker = DeepSort(
            max_age=30,
            n_init=3,
            nms_max_overlap=1.0,
            max_cosine_distance=0.3,
            nn_budget=None,
            embedder="mobilenet",
            half=True,
            embedder_gpu=False
        )
        print("‚úÖ DeepSORT ƒë√£ s·∫µn s√†ng!")
        
        # ROI
        self.roi = None
        self.roi_length_m = 20.0
        self.meter_per_pixel = None
        
        # Tracking history
        self.track_history = defaultdict(lambda: deque(maxlen=30))
        self.track_smoothed_speed = {}
        
        # Stats
        self.frame_count = 0
        self.fps = 0
        self.fps_start_time = time.time()
        self.fps_counter = 0
        self.total_frames = 0
        
        # UI
        self.instruction_text = ""
        self.instruction_color = (255, 255, 255)
        
        # Setup source
        if self.mode == "local":
            self.setup_local_video()
        else:
            self.setup_stream()
    
    # ==================== SETUP VIDEO LOCAL ====================
    def setup_local_video(self):
        """M·ªü video t·ª´ file local"""
        if not self.video_path or not os.path.exists(self.video_path):
            print(" File video kh√¥ng t·ªìn t·∫°i!")
            self.running = False
            return
        
        self.cap = cv2.VideoCapture(self.video_path)
        if not self.cap.isOpened():
            print(" Kh√¥ng th·ªÉ m·ªü video!")
            self.running = False
            return
        
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        print("\n" + "="*70)
        print("‚úÖ ƒê√É T·∫¢I VIDEO TH√ÄNH C√îNG!")
        print("="*70)
        print(f"üìÅ File: {os.path.basename(self.video_path)}")
        print(f"üé¨ T·ªïng frames: {self.total_frames}")
        print(f"‚è±Ô∏è  FPS: {fps:.2f}")
        print(f"‚è∞ Th·ªùi l∆∞·ª£ng: {self.total_frames/fps:.2f}s")
        print("="*70 + "\n")
    
    # ==================== SETUP STREAM ====================
    def setup_stream(self):
        """K·∫øt n·ªëi WebSocket stream"""
        print(f"üîå ƒêang k·∫øt n·ªëi ƒë·∫øn VPS: {VPS_URL}")
    
    # ==================== WEBSOCKET CALLBACKS ====================
    def on_message(self, ws, message):
        try:
            if len(message) < 10:
                return
            
            if message[0] != 0xFF or message[1] != 0xD8:
                return
            
            nparr = np.frombuffer(message, dtype=np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if frame is not None:
                self.frame_queue.append(frame)
                if len(self.frame_queue) > 3:
                    self.frame_queue.pop(0)
        except Exception as e:
            print(f"Ô∏è  L·ªói gi·∫£i m√£: {e}")
    
    def on_error(self, ws, error):
        print(f" L·ªói WebSocket: {error}")
    
    def on_close(self, ws, close_status_code, close_msg):
        print("üëã WebSocket ƒë√£ ƒë√≥ng")
        self.running = False
    
    def on_open(self, ws):
        print("\n" + "="*70)
        print("‚úÖ ƒê√É K·∫æT N·ªêI TH√ÄNH C√îNG V·ªöI VPS!")
        print("="*70)
        print("üì± B√¢y gi·ªù h√£y b·∫Øt ƒë·∫ßu stream video t·ª´ ƒëi·ªán tho·∫°i")
        print("="*70)
        self.print_instructions()
    
    # ==================== PRINT INSTRUCTIONS ====================
    def print_instructions(self):
        print("\nüéÆ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
        print("   ‚îú‚îÄ [R] Ch·ªçn v√πng quan s√°t (ROI)")
        print("   ‚îú‚îÄ [C] Hi·ªáu ch·ªânh t·ªâ l·ªá th·ª±c (Calibrate)")
        if self.mode == "local":
            print("   ‚îú‚îÄ [SPACE] T·∫°m d·ª´ng/Ti·∫øp t·ª•c")
            print("   ‚îú‚îÄ [‚Üê/‚Üí] Tua l√πi/tua t·ªõi 5 gi√¢y")
        print("   ‚îî‚îÄ [Q] Tho√°t ch∆∞∆°ng tr√¨nh")
        print("="*70 + "\n")
    
    # ==================== V·∫º TH√îNG B√ÅO ====================
    def draw_instruction(self, frame):
        """V·∫Ω th√¥ng b√°o h∆∞·ªõng d·∫´n"""
        if self.instruction_text:
            overlay = frame.copy()
            h, w = frame.shape[:2]
            
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            thickness = 2
            
            lines = self.instruction_text.split('\n')
            y_offset = 50
            max_width = 0
            
            for line in lines:
                (text_w, text_h), _ = cv2.getTextSize(line, font, font_scale, thickness)
                max_width = max(max_width, text_w)
            
            padding = 20
            box_h = len(lines) * 35 + padding * 2
            box_w = max_width + padding * 2
            box_x = (w - box_w) // 2
            box_y = y_offset - padding
            
            cv2.rectangle(overlay, (box_x, box_y), (box_x + box_w, box_y + box_h), 
                         (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
            cv2.rectangle(frame, (box_x, box_y), (box_x + box_w, box_y + box_h),
                         self.instruction_color, 2)
            
            for i, line in enumerate(lines):
                (text_w, text_h), _ = cv2.getTextSize(line, font, font_scale, thickness)
                text_x = (w - text_w) // 2
                text_y = y_offset + i * 35 + text_h
                
                cv2.putText(frame, line, (text_x + 2, text_y + 2), font, 
                           font_scale, (0, 0, 0), thickness + 1)
                cv2.putText(frame, line, (text_x, text_y), font, 
                           font_scale, self.instruction_color, thickness)
    
    # ==================== ROI SELECTION ====================
    def select_roi(self, frame):
        """Ch·ªçn v√πng quan s√°t"""
        print("\n" + "="*70)
        print("üéØ CH·ªåN V√ôNG QUAN S√ÅT (ROI)")
        print("="*70)
        print("üìç Click chu·ªôt TR√ÅI ƒë·ªÉ ch·ªçn c√°c ƒë·ªânh")
        print("üìç Click chu·ªôt PH·∫¢I ƒë·ªÉ ƒë√≥ng polygon")
        print("‚úÖ Nh·∫•n ENTER ƒë·ªÉ x√°c nh·∫≠n |  ESC ƒë·ªÉ h·ªßy")
        print("="*70 + "\n")
        
        tmp = frame.copy()
        roi_points = []
        instruction = "Click chuot TRAI de chon cac dinh\nClick chuot PHAI de dong polygon\nENTER: Xac nhan | ESC: Huy"
        point_count = 0
        
        def mouse_callback(event, x, y, flags, param):
            nonlocal roi_points, tmp, point_count, instruction
            
            if event == cv2.EVENT_LBUTTONDOWN:
                roi_points.append((x, y))
                point_count += 1
                
                cv2.circle(tmp, (x, y), 7, (0, 255, 0), -1)
                cv2.circle(tmp, (x, y), 9, (255, 255, 255), 2)
                cv2.putText(tmp, str(point_count), (x + 15, y - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                
                if len(roi_points) > 1:
                    cv2.line(tmp, roi_points[-2], roi_points[-1], (0, 255, 255), 3)
                
                if len(roi_points) == 1:
                    instruction = f"Da chon {len(roi_points)} dinh\nChon them cac dinh khac"
                    print(f"‚úÖ ƒê√£ ch·ªçn ƒëi·ªÉm {point_count}")
                elif len(roi_points) == 2:
                    instruction = f"Da chon {len(roi_points)} dinh\nChon it nhat 1 dinh nua"
                    print(f"‚úÖ ƒê√£ ch·ªçn ƒëi·ªÉm {point_count}")
                else:
                    instruction = f"Da chon {len(roi_points)} dinh\nClick PHAI de dong, hoac chon them"
                    print(f"‚úÖ ƒê√£ ch·ªçn ƒëi·ªÉm {point_count}")
                
            elif event == cv2.EVENT_RBUTTONDOWN and len(roi_points) >= 3:
                cv2.line(tmp, roi_points[-1], roi_points[0], (0, 255, 255), 3)
                cv2.polylines(tmp, [np.array(roi_points, np.int32)], True, (0, 0, 255), 3)
                instruction = f"Polygon da dong ({len(roi_points)} dinh)\nNhan ENTER de xac nhan"
                print(f"‚úÖ ƒê√£ ƒë√≥ng polygon v·ªõi {len(roi_points)} ƒë·ªânh")
            
            self.instruction_text = instruction
            self.instruction_color = (0, 255, 255)
            display = tmp.copy()
            self.draw_instruction(display)
            cv2.imshow("Chon ROI", display)
        
        cv2.namedWindow("Chon ROI")
        cv2.setMouseCallback("Chon ROI", mouse_callback)
        
        self.instruction_text = instruction
        self.instruction_color = (0, 255, 255)
        display = tmp.copy()
        self.draw_instruction(display)
        cv2.imshow("Chon ROI", display)
        
        while True:
            key = cv2.waitKey(1) & 0xFF
            if key == 13:
                if len(roi_points) >= 3:
                    print("‚úÖ ƒê√£ x√°c nh·∫≠n ROI")
                    break
                else:
                    print("Ô∏è  C·∫ßn √≠t nh·∫•t 3 ƒë·ªânh!")
                    self.instruction_text = "CAN IT NHAT 3 DINH!\nChon them cac dinh"
                    self.instruction_color = (0, 0, 255)
                    display = tmp.copy()
                    self.draw_instruction(display)
                    cv2.imshow("Chon ROI", display)
            elif key == 27:
                roi_points = []
                print(" ƒê√£ h·ªßy ch·ªçn ROI")
                break
        
        cv2.destroyWindow("Chon ROI")
        self.instruction_text = ""
        
        if len(roi_points) >= 3:
            self.roi = np.array(roi_points, np.int32)
            print(f"\nüéØ ROI ƒë√£ ƒë∆∞·ª£c ch·ªçn v·ªõi {len(self.roi)} ƒë·ªânh\n")
    
    # ==================== CALIBRATE ====================
    def calibrate_scale(self, frame):
        """Hi·ªáu ch·ªânh t·ªâ l·ªá"""
        print("\n" + "="*70)
        print("üìè HI·ªÜU CH·ªàNH T·ªà L·ªÜ TH·ª∞C")
        print("="*70)
        print("üìç Click 2 ƒëi·ªÉm c√≥ kho·∫£ng c√°ch th·ª±c bi·∫øt tr∆∞·ªõc")
        print("‚úÖ Nh·∫≠p kho·∫£ng c√°ch (m√©t) |  ESC ƒë·ªÉ h·ªßy")
        print("="*70 + "\n")
        
        tmp = frame.copy()
        pts = []
        instruction = "Click 2 diem co khoang cach thuc biet truoc"
        
        def mouse_cb(event, x, y, flags, param):
            nonlocal pts, tmp, instruction
            
            if event == cv2.EVENT_LBUTTONDOWN:
                pts.append((x, y))
                
                cv2.circle(tmp, (x, y), 8, (0, 255, 0), -1)
                cv2.circle(tmp, (x, y), 10, (255, 255, 255), 2)
                
                label = "DIEM 1" if len(pts) == 1 else "DIEM 2"
                cv2.putText(tmp, label, (x + 15, y - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if len(pts) == 1:
                    instruction = "Da chon DIEM 1\nChon DIEM 2"
                    print("‚úÖ ƒê√£ ch·ªçn ƒëi·ªÉm 1")
                elif len(pts) == 2:
                    cv2.line(tmp, pts[0], pts[1], (0, 255, 255), 3)
                    
                    dist_px = np.linalg.norm(np.array(pts[1]) - np.array(pts[0]))
                    
                    mid_x = (pts[0][0] + pts[1][0]) // 2
                    mid_y = (pts[0][1] + pts[1][1]) // 2
                    cv2.putText(tmp, f"{dist_px:.1f} pixels", (mid_x, mid_y - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                    
                    instruction = f"Khoang cach: {dist_px:.1f} pixels\nNhap khoang cach thuc vao console"
                    print(f"‚úÖ ƒê√£ ch·ªçn ƒëi·ªÉm 2")
                    print(f"üìè Kho·∫£ng c√°ch: {dist_px:.1f} pixels")
                
                self.instruction_text = instruction
                self.instruction_color = (0, 255, 255)
                display = tmp.copy()
                self.draw_instruction(display)
                cv2.imshow("Hieu chinh ti le", display)
        
        cv2.namedWindow("Hieu chinh ti le")
        cv2.setMouseCallback("Hieu chinh ti le", mouse_cb)
        
        self.instruction_text = instruction
        self.instruction_color = (0, 255, 255)
        display = tmp.copy()
        self.draw_instruction(display)
        cv2.imshow("Hieu chinh ti le", display)
        
        while len(pts) < 2:
            key = cv2.waitKey(1) & 0xFF
            if key == 27:
                pts = []
                print(" ƒê√£ h·ªßy hi·ªáu ch·ªânh")
                break
        
        cv2.destroyWindow("Hieu chinh ti le")
        self.instruction_text = ""
        
        if len(pts) == 2:
            p1, p2 = np.array(pts[0], float), np.array(pts[1], float)
            pixel_dist = float(np.linalg.norm(p2 - p1))
            
            print(f"üìè Kho·∫£ng c√°ch: {pixel_dist:.2f} pixels")
            
            try:
                real_dist = float(input("‚û°Ô∏è  Nh·∫≠p kho·∫£ng c√°ch th·ª±c (m√©t): "))
                
                if real_dist > 0:
                    self.meter_per_pixel = real_dist / pixel_dist
                    print("="*70)
                    print(f"‚úÖ ƒê√É HI·ªÜU CH·ªàNH!")
                    print(f"   1 pixel = {self.meter_per_pixel:.6f} m√©t")
                    print("="*70 + "\n")
            except:
                print(" Gi√° tr·ªã kh√¥ng h·ª£p l·ªá!\n")
    
    # ==================== T√çNH V·∫¨N T·ªêC ====================
    def calculate_speed(self, history):
        if len(history) >= 2:
            pt1 = history[-2][:2]
            pt2 = history[-1][:2]
            dt = history[-1][2] - history[-2][2]
            
            if dt > 0.001:
                dist_pixels = np.linalg.norm(np.array(pt2) - np.array(pt1))
                
                if self.meter_per_pixel:
                    dist_meters = dist_pixels * self.meter_per_pixel
                else:
                    if self.roi is not None:
                        roi_length_pixels = cv2.arcLength(self.roi, True)
                        self.meter_per_pixel = self.roi_length_m / roi_length_pixels
                        dist_meters = dist_pixels * self.meter_per_pixel
                    else:
                        dist_meters = dist_pixels * 0.05
                
                speed_kmh = (dist_meters / dt) * 3.6
                return min(max(speed_kmh, 0.0), 120.0)
        
        return 0.0
    
    # ==================== X·ª¨ L√ù FRAME ====================
    def process_frame(self, frame):
        t_now = time.time()
        
        # Detection
        results = self.model.predict(frame, conf=0.25, iou=0.5, imgsz=640, verbose=False)
        
        detections = []
        r = results[0]
        
        if hasattr(r, 'boxes'):
            for box in r.boxes:
                cls_id = int(box.cls[0].cpu().numpy())
                cls_name = self.model.names[cls_id]
                
                if cls_name in CUSTOM_CLASSES:
                    conf = float(box.conf[0].cpu().numpy())
                    threshold = CLASS_CONF_THRESHOLDS.get(cls_name, 0.35)
                    
                    if conf >= threshold:
                        xyxy = box.xyxy[0].cpu().numpy()
                        x1, y1, x2, y2 = xyxy.astype(int)
                        detections.append(([x1, y1, x2-x1, y2-y1], conf, cls_name))
        
        # Tracking
        tracks = self.tracker.update_tracks(detections, frame=frame)
        
        in_roi_ids = set()
        in_roi_classes = []
        speeds_kmh = []
        
        for tr in tracks:
            if not tr.is_confirmed():
                continue
            
            track_id = tr.track_id
            left, top, right, bottom = map(int, tr.to_ltrb())
            cx, cy = int((left + right) / 2), int((top + bottom) / 2)
            
            self.track_history[track_id].append((cx, cy, t_now))
            
            in_roi = (
                self.roi is not None and
                cv2.pointPolygonTest(self.roi, (cx, cy), False) >= 0
            )
            
            if in_roi:
                in_roi_ids.add(track_id)
                cls_name = tr.get_det_class() if hasattr(tr, 'get_det_class') else "unknown"
                in_roi_classes.append(cls_name)
                
                speed_kmh = self.calculate_speed(self.track_history[track_id])
                alpha = 0.3
                prev = self.track_smoothed_speed.get(track_id, speed_kmh)
                smooth = alpha * speed_kmh + (1 - alpha) * prev
                self.track_smoothed_speed[track_id] = smooth
                
                if smooth > 0.5:
                    speeds_kmh.append(smooth)
                
                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(frame, f"ID:{track_id} {smooth:.1f}km/h",
                           (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX,
                           0.5, (0, 255, 0), 2)
            else:
                cv2.rectangle(frame, (left, top), (right, bottom), (128, 128, 128), 1)
        
        # Stats
        count_in_roi = len(in_roi_ids)
        equiv_count = sum(VEHICLE_EQUIV.get(cls, 1.0) for cls in in_roi_classes)
        avg_speed_kmh = float(np.mean(speeds_kmh)) if speeds_kmh else 0.0
        
        # V·∫Ω ROI
        if self.roi is not None:
            cv2.polylines(frame, [self.roi], True, (0, 0, 255), 3)
            for pt in self.roi:
                cv2.circle(frame, tuple(pt), 6, (0, 255, 255), -1)
                cv2.circle(frame, tuple(pt), 8, (255, 255, 255), 2)
        
        # C·∫£nh b√°o
        is_congested = (equiv_count > THRESHOLD_COUNT and avg_speed_kmh < THRESHOLD_SPEED)
        
        # V·∫Ω UI
        overlay = frame.copy()
        cv2.rectangle(overlay, (5, 5), (450, 200), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        cv2.rectangle(frame, (5, 5), (450, 200), (255, 255, 255), 2)
        
        y_offset = 30
        cv2.putText(frame, f"Frame: {self.frame_count}/{self.total_frames if self.mode=='local' else '‚àû'}", 
                   (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += 30
        
        cv2.putText(frame, f"FPS: {self.fps:.1f}", (15, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += 30
        
        cv2.putText(frame, f"Xe trong ROI: {count_in_roi}", (15, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        y_offset += 30
        
        cv2.putText(frame, f"Tuong duong: {equiv_count:.1f} xe may", (15, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        y_offset += 30
        
        cv2.putText(frame, f"Van toc TB: {avg_speed_kmh:.2f} km/h", (15, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        y_offset += 30
        
        if is_congested:
            cv2.putText(frame, "! CANH BAO KET XE !", (15, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)
        else:
            cv2.putText(frame, "Hoat dong binh thuong", (15, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Help
        h, w = frame.shape[:2]
        help_y = h - 80
        cv2.rectangle(frame, (w - 250, help_y - 10), (w - 10, h - 10), (0, 0, 0), -1)
        cv2.rectangle(frame, (w - 250, help_y - 10), (w - 10, h - 10), (255, 255, 255), 1)
        
        cv2.putText(frame, "[R] Chon ROI", (w - 240, help_y + 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, "[C] Hieu chinh", (w - 240, help_y + 35),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, "[Q] Thoat", (w - 240, help_y + 55),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return frame
    
    # ==================== RUN LOCAL VIDEO ====================
    def run_local(self):
        """Ch·∫°y x·ª≠ l√Ω video local"""
        cv2.namedWindow('Traffic Monitor', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Traffic Monitor', 1280, 720)
        
        paused = False
        
        print("üé• ƒêang x·ª≠ l√Ω video...")
        self.print_instructions()
        
        while self.running:
            try:
                if not paused:
                    ret, frame = self.cap.read()
                    if not ret:
                        print("\n‚úÖ ƒê√£ x·ª≠ l√Ω h·∫øt video!")
                        break
                    
                    self.frame_count += 1
                    
                    # Process
                    processed = self.process_frame(frame)
                    
                    # FPS
                    self.fps_counter += 1
                    if self.fps_counter % 10 == 0:
                        fps_end = time.time()
                        self.fps = 10 / (fps_end - self.fps_start_time)
                        self.fps_start_time = fps_end
                    
                    cv2.imshow('Traffic Monitor', processed)
                    
                    if self.frame_count % 30 == 0:
                        progress = (self.frame_count / self.total_frames) * 100
                        print(f"‚úÖ {self.frame_count}/{self.total_frames} ({progress:.1f}%) | FPS: {self.fps:.1f}")
                else:
                    # Paused - ch·ªâ hi·ªÉn th·ªã frame hi·ªán t·∫°i
                    cv2.imshow('Traffic Monitor', processed)
                
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == ord('Q'):
                    print("\nüõë ƒêang d·ª´ng...")
                    break
                elif key == ord('r') or key == ord('R'):
                    ret, frame = self.cap.read()
                    if ret:
                        current_pos = self.cap.get(cv2.CAP_PROP_POS_FRAMES)
                        self.cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos - 1)
                        print("\nüéØ B·∫Øt ƒë·∫ßu ch·ªçn ROI...")
                        self.select_roi(frame)
                elif key == ord('c') or key == ord('C'):
                    ret, frame = self.cap.read()
                    if ret:
                        current_pos = self.cap.get(cv2.CAP_PROP_POS_FRAMES)
                        self.cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos - 1)
                        print("\nüìè B·∫Øt ƒë·∫ßu hi·ªáu ch·ªânh...")
                        self.calibrate_scale(frame)
                elif key == 32:  # SPACE
                    paused = not paused
                    status = "‚è∏Ô∏è  T·∫†M D·ª™NG" if paused else "‚ñ∂Ô∏è  TI·∫æP T·ª§C"
                    print(f"\n{status}")
                elif key == 81:  # Left arrow
                    current = self.cap.get(cv2.CAP_PROP_POS_FRAMES)
                    fps = self.cap.get(cv2.CAP_PROP_FPS)
                    new_pos = max(0, current - fps * 5)
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, new_pos)
                    print(f"‚è™ Tua l√πi 5 gi√¢y")
                elif key == 83:  # Right arrow
                    current = self.cap.get(cv2.CAP_PROP_POS_FRAMES)
                    fps = self.cap.get(cv2.CAP_PROP_FPS)
                    new_pos = min(self.total_frames, current + fps * 5)
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, new_pos)
                    print(f"‚è© Tua t·ªõi 5 gi√¢y")
                    
            except KeyboardInterrupt:
                print("\nüõë Nh·∫≠n Ctrl+C...")
                break
            except Exception as e:
                print(f" L·ªói: {e}")
                import traceback
                traceback.print_exc()
        
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        
        print("\n" + "="*70)
        print("üëã HO√ÄN T·∫§T X·ª¨ L√ù VIDEO")
        print(f"üìä T·ªïng frames: {self.frame_count}")
        print("="*70 + "\n")
    
    # ==================== RUN STREAM ====================
    def run_stream(self):
        """Ch·∫°y x·ª≠ l√Ω stream t·ª´ phone"""
        ws = websocket.WebSocketApp(
            VPS_URL,
            on_message=self.on_message,
            on_error=self.on_error,
            on_close=self.on_close,
            on_open=self.on_open
        )
        
        ws_thread = threading.Thread(target=ws.run_forever)
        ws_thread.daemon = True
        ws_thread.start()
        
        cv2.namedWindow('Traffic Monitor', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Traffic Monitor', 1280, 720)
        
        print("üé• ƒêang ch·ªù video stream...")
        
        while self.running:
            try:
                if len(self.frame_queue) > 0:
                    frame = self.frame_queue.pop(0)
                    self.frame_count += 1
                    
                    processed = self.process_frame(frame)
                    
                    self.fps_counter += 1
                    if self.fps_counter % 10 == 0:
                        fps_end = time.time()
                        self.fps = 10 / (fps_end - self.fps_start_time)
                        self.fps_start_time = fps_end
                    
                    cv2.imshow('Traffic Monitor', processed)
                    
                    if self.frame_count % 30 == 0:
                        print(f"‚úÖ ƒê√£ x·ª≠ l√Ω {self.frame_count} frames | FPS: {self.fps:.1f}")
                
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == ord('Q'):
                    print("\nüõë ƒêang d·ª´ng...")
                    break
                elif key == ord('r') or key == ord('R'):
                    if len(self.frame_queue) > 0:
                        print("\nüéØ B·∫Øt ƒë·∫ßu ch·ªçn ROI...")
                        self.select_roi(self.frame_queue[0])
                    else:
                        print("\nÔ∏è  Ch∆∞a c√≥ video stream!")
                elif key == ord('c') or key == ord('C'):
                    if len(self.frame_queue) > 0:
                        print("\nüìè B·∫Øt ƒë·∫ßu hi·ªáu ch·ªânh...")
                        self.calibrate_scale(self.frame_queue[0])
                    else:
                        print("\nÔ∏è  Ch∆∞a c√≥ video stream!")
                    
            except KeyboardInterrupt:
                print("\nüõë Nh·∫≠n Ctrl+C...")
                break
            except Exception as e:
                print(f" L·ªói: {e}")
                import traceback
                traceback.print_exc()
        
        ws.close()
        cv2.destroyAllWindows()
        
        print("\n" + "="*70)
        print("üëã STREAM ƒê√É D·ª™NG")
        print(f"üìä T·ªïng frames: {self.frame_count}")
        print("="*70 + "\n")
    
    # ==================== RUN ====================
    def run(self):
        """Ch·∫°y ch∆∞∆°ng tr√¨nh"""
        if self.mode == "local":
            self.run_local()
        else:
            self.run_stream()


# ==================== GUI CH·ªåN CH·ªÇ ƒê·ªò ====================
class ModeSelectionGUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("üö¶ Traffic Monitor - Ch·ªçn ch·∫ø ƒë·ªô")
        self.root.geometry("500x300")
        self.root.resizable(False, False)
        
        self.mode = None
        self.video_path = None
        
        # Title
        title = tk.Label(
            self.root,
            text="üö¶ H·ªÜ TH·ªêNG GI√ÅM S√ÅT GIAO TH√îNG",
            font=("Arial", 16, "bold"),
            fg="#2C3E50"
        )
        title.pack(pady=20)
        
        subtitle = tk.Label(
            self.root,
            text="Ph√°t hi·ªán k·∫πt xe b·∫±ng YOLOv8 + DeepSORT",
            font=("Arial", 10),
            fg="#7F8C8D"
        )
        subtitle.pack(pady=5)
        
        # Buttons frame
        btn_frame = tk.Frame(self.root)
        btn_frame.pack(pady=30)
        
        # Button 1: Import Video
        btn1 = tk.Button(
            btn_frame,
            text="üìÅ Import Video t·ª´ M√°y",
            font=("Arial", 12, "bold"),
            bg="#3498DB",
            fg="white",
            width=25,
            height=2,
            command=self.select_local_video,
            cursor="hand2"
        )
        btn1.pack(pady=10)
        
        # Button 2: Stream
        btn2 = tk.Button(
            btn_frame,
            text="üì± Stream t·ª´ ƒêi·ªán tho·∫°i",
            font=("Arial", 12, "bold"),
            bg="#2ECC71",
            fg="white",
            width=25,
            height=2,
            command=self.select_stream,
            cursor="hand2"
        )
        btn2.pack(pady=10)
        
        # Footer
        footer = tk.Label(
            self.root,
            text="Powered by YOLOv8 + DeepSORT",
            font=("Arial", 8),
            fg="#95A5A6"
        )
        footer.pack(side=tk.BOTTOM, pady=10)
        
        self.root.mainloop()
    
    def select_local_video(self):
        """Ch·ªçn video t·ª´ m√°y"""
        file_path = filedialog.askopenfilename(
            title="Ch·ªçn video",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv *.flv"),
                ("All files", "*.*")
            ]
        )
        
        if file_path:
            self.mode = "local"
            self.video_path = file_path
            self.root.destroy()
        else:
            messagebox.showwarning("C·∫£nh b√°o", "B·∫°n ch∆∞a ch·ªçn file video!")
    
    def select_stream(self):
        """Ch·ªçn ch·∫ø ƒë·ªô stream"""
        result = messagebox.askyesno(
            "X√°c nh·∫≠n",
            "B·∫°n s·∫Ω stream video t·ª´ ƒëi·ªán tho·∫°i.\n\n"
            "ƒê·∫£m b·∫£o:\n"
            "1. VPS server ƒëang ch·∫°y\n"
            "2. Caddy HTTPS ƒëang ch·∫°y\n"
            "3. ƒêi·ªán tho·∫°i s·∫Ω truy c·∫≠p: https://traffic058.io.vn\n\n"
            "Ti·∫øp t·ª•c?"
        )
        
        if result:
            self.mode = "stream"
            self.video_path = None
            self.root.destroy()
    
    def get_selection(self):
        """L·∫•y l·ª±a ch·ªçn"""
        return self.mode, self.video_path


# ==================== MAIN ====================
def main():
    print("\n" + "="*70)
    print("üö¶ H·ªÜ TH·ªêNG GI√ÅM S√ÅT GIAO TH√îNG - PH√ÅT HI·ªÜN K·∫∏T XE")
    print("="*70)
    print("üì° H·ªó tr·ª£ 2 ch·∫ø ƒë·ªô:")
    print("   1. Import video t·ª´ m√°y local")
    print("   2. Stream tr·ª±c ti·∫øp t·ª´ ƒëi·ªán tho·∫°i")
    print("="*70 + "\n")
    
    try:
        # Hi·ªÉn th·ªã GUI ch·ªçn ch·∫ø ƒë·ªô
        gui = ModeSelectionGUI()
        mode, video_path = gui.get_selection()
        
        if mode is None:
            print("üëã Ng∆∞·ªùi d√πng h·ªßy ch∆∞∆°ng tr√¨nh")
            return
        
        # Kh·ªüi t·∫°o v√† ch·∫°y
        monitor = TrafficMonitor(mode=mode, video_path=video_path)
        
        if monitor.running:
            monitor.run()
        
    except KeyboardInterrupt:
        print("\nüëã T·∫°m bi·ªát!")
    except Exception as e:
        print(f"\n L·ªói nghi√™m tr·ªçng: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()